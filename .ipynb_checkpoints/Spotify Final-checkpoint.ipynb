{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.6/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: wordcloud in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.6/site-packages (from wordcloud)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /opt/conda/lib/python3.6/site-packages (from wordcloud)\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already up-to-date: nltk in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already up-to-date: singledispatch in /opt/conda/lib/python3.6/site-packages (from nltk)\n",
      "Requirement already up-to-date: six in /opt/conda/lib/python3.6/site-packages (from nltk)\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import spotipy\n",
    "from pandas.io.json import json_normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import string\n",
    "!{sys.executable} -m pip install Pillow\n",
    "!{sys.executable} -m pip install wordcloud\n",
    "!{sys.executable} -m pip install -U nltk\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "# https://developer.spotify.com/console/get-playlist-tracks/?playlist_id=37i9dQZF1DX5Ejj0EkURtP&market=&fields=&limit=&offset= \n",
    "# use above website to generate token\n",
    "token = \"BQBPFqaMv3Hou4Cj48eauA7mG8cXlVxXTaImA2j7Tzjm5utxkpN9s0JgroRzEVjSIU7AOZarl73yxKcsUT7_5lNeVna-2OGnto6PzEOb0RYL9AXfBP3jpT15wM2wHGAp7FvnAWo__oeskGKWiQ\"\n",
    "# https://genius.com/api-clients ==> use this website to generate token\n",
    "genius_token = 'V3BxSvKtWKcSlonUDfqeKWZmRKK3qjGyAGJCRqxm8awvuWI65nm7WFrYmnn3acIu'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this gets the 2010s playlist - have to update token if it expires\n",
    "r_10s = requests.get(\"https://api.spotify.com/v1/playlists/37i9dQZF1DX5Ejj0EkURtP\", headers={'Authorization': 'Bearer ' + token})\n",
    "r_00s = requests.get(\"https://api.spotify.com/v1/playlists/37i9dQZF1DX4o1oenSJRJd\", headers={'Authorization': 'Bearer ' + token})\n",
    "r_90s = requests.get(\"https://api.spotify.com/v1/playlists/37i9dQZF1DXbTxeAdrVG2l\", headers={'Authorization': 'Bearer ' + token})\n",
    "r_80s = requests.get(\"https://api.spotify.com/v1/playlists/37i9dQZF1DX4UtSsGT1Sbe\", headers={'Authorization': 'Bearer ' + token})\n",
    "r_70s = requests.get(\"https://api.spotify.com/v1/playlists/37i9dQZF1DWTJ7xPn4vNaz\", headers={'Authorization': 'Bearer ' + token})\n",
    "r_60s = requests.get(\"https://api.spotify.com/v1/playlists/37i9dQZF1DXaKIA8E7WcJj\", headers={'Authorization': 'Bearer ' + token})\n",
    "r_50s = requests.get(\"https://api.spotify.com/v1/playlists/37i9dQZF1DWSV3Tk4GO2fq\", headers={'Authorization': 'Bearer ' + token})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tracks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-a002fd37d238>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mjson_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_10s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplaylists_10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tracks\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"items\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'track'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'artists'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'added_at'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'track'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'popularity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'track'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'track'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'track'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'duration_ms'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplaylists_10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplaylists_10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'external_urls'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'href'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'uri'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplaylists_10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tracks'"
     ]
    }
   ],
   "source": [
    "json_data = r_10s.json()\n",
    "playlists_10 = json_normalize(json_data[\"tracks\"][\"items\"], [['track', 'artists']], ['added_at', ['track', 'popularity'], ['track', 'id'], ['track', 'name'], ['track', 'duration_ms']], errors='ignore')\n",
    "playlists_10 = playlists_10.drop(columns=['external_urls', 'href', 'type', 'uri'])\n",
    "\n",
    "playlists_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "json_data = r_10s.json()\n",
    "playlists_10 = json_normalize(json_data[\"tracks\"][\"items\"], [['track', 'artists']], ['added_at', ['track', 'popularity'], ['track', 'id'], ['track', 'name'], ['track', 'duration_ms']], errors='ignore')\n",
    "playlists_10 = playlists_10.drop(columns=['external_urls', 'href', 'type', 'uri'])\n",
    "\n",
    "json_data_00 = r_00s.json()\n",
    "playlists_00 = json_normalize(json_data_00[\"tracks\"][\"items\"], [['track', 'artists']], ['added_at', ['track', 'popularity'], ['track', 'id'], ['track', 'name'], ['track', 'duration_ms']], errors='ignore')\n",
    "playlists_00 = playlists_00.drop(columns=['external_urls', 'href', 'type', 'uri'])\n",
    "\n",
    "json_data_90 = r_90s.json()\n",
    "playlists_90 = json_normalize(json_data_90[\"tracks\"][\"items\"], [['track', 'artists']], ['added_at', ['track', 'popularity'], ['track', 'id'], ['track', 'name'], ['track', 'duration_ms']], errors='ignore')\n",
    "playlists_90 = playlists_90.drop(columns=['external_urls', 'href', 'type', 'uri'])\n",
    "\n",
    "json_data_80 = r_80s.json()\n",
    "playlists_80 = json_normalize(json_data_80[\"tracks\"][\"items\"], [['track', 'artists']], ['added_at', ['track', 'popularity'], ['track', 'id'], ['track', 'name'], ['track', 'duration_ms']], errors='ignore')\n",
    "playlists_80 = playlists_80.drop(columns=['external_urls', 'href', 'type', 'uri'])\n",
    "\n",
    "json_data_70 = r_70s.json()\n",
    "playlists_70 = json_normalize(json_data_70[\"tracks\"][\"items\"], [['track', 'artists']], ['added_at', ['track', 'popularity'], ['track', 'id'], ['track', 'name'], ['track', 'duration_ms']], errors='ignore')\n",
    "playlists_70 = playlists_70.drop(columns=['external_urls', 'href', 'type', 'uri'])\n",
    "\n",
    "json_data_60 = r_60s.json()\n",
    "playlists_60 = json_normalize(json_data_60[\"tracks\"][\"items\"], [['track', 'artists']], ['added_at', ['track', 'popularity'], ['track', 'id'], ['track', 'name'], ['track', 'duration_ms']], errors='ignore')\n",
    "playlists_60 = playlists_60.drop(columns=['external_urls', 'href', 'type', 'uri'])\n",
    "\n",
    "json_data_50 = r_50s.json()\n",
    "playlists_50 = json_normalize(json_data_50[\"tracks\"][\"items\"], [['track', 'artists']], ['added_at', ['track', 'popularity'], ['track', 'id'], ['track', 'name'], ['track', 'duration_ms']], errors='ignore')\n",
    "playlists_50 = playlists_50.drop(columns=['external_urls', 'href', 'type', 'uri'])\n",
    "\n",
    "playlists_80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aggregation_functions = {'name': 'first', 'track.id': 'first', 'track.duration_ms': 'first', 'added_at': 'first', 'track.popularity' : 'first'}\n",
    "df_new = playlists_10.groupby(playlists_10['track.name']).aggregate(aggregation_functions)\n",
    "\n",
    "aggregation_functions = {'name': 'first', 'track.id': 'first', 'track.duration_ms': 'first', 'added_at': 'first', 'track.popularity' : 'first'}\n",
    "grouped_00 = playlists_00.groupby(playlists_00['track.name']).aggregate(aggregation_functions)\n",
    "\n",
    "aggregation_functions = {'name': 'first', 'track.id': 'first', 'track.duration_ms': 'first', 'added_at': 'first', 'track.popularity' : 'first'}\n",
    "grouped_90 = playlists_90.groupby(playlists_90['track.name']).aggregate(aggregation_functions)\n",
    "\n",
    "aggregation_functions = {'name': 'first', 'track.id': 'first', 'track.duration_ms': 'first', 'added_at': 'first', 'track.popularity' : 'first'}\n",
    "grouped_80 = playlists_80.groupby(playlists_80['track.name']).aggregate(aggregation_functions)\n",
    "\n",
    "aggregation_functions = {'name': 'first', 'track.id': 'first', 'track.duration_ms': 'first', 'added_at': 'first', 'track.popularity' : 'first'}\n",
    "grouped_70 = playlists_70.groupby(playlists_70['track.name']).aggregate(aggregation_functions)\n",
    "\n",
    "aggregation_functions = {'name': 'first', 'track.id': 'first', 'track.duration_ms': 'first', 'added_at': 'first', 'track.popularity' : 'first'}\n",
    "grouped_60 = playlists_60.groupby(playlists_60['track.name']).aggregate(aggregation_functions)\n",
    "\n",
    "aggregation_functions = {'name': 'first', 'track.id': 'first', 'track.duration_ms': 'first', 'added_at': 'first', 'track.popularity' : 'first'}\n",
    "grouped_50 = playlists_50.groupby(playlists_50['track.name']).aggregate(aggregation_functions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "track_ids = df_new['track.id'].tolist()\n",
    "track_str = '%2C'.join(track_ids)\n",
    "t = requests.get(\"https://api.spotify.com/v1/audio-features?ids=\" + track_str, headers={'Authorization': 'Bearer ' + token})\n",
    "track_info_df = json_normalize(t.json()['audio_features'])\n",
    "track_info_df = track_info_df.drop(columns=['analysis_url', 'mode', 'track_href', 'type', 'uri'])\n",
    "\n",
    "track_ids_00 = grouped_00['track.id'].tolist()\n",
    "track_str_00 = '%2C'.join(track_ids_00)\n",
    "t_00s = requests.get(\"https://api.spotify.com/v1/audio-features?ids=\" + track_str_00, headers={'Authorization': 'Bearer ' + token})\n",
    "track_info_00 = json_normalize(t_00s.json()['audio_features'])\n",
    "track_info_00 = track_info_00.drop(columns=['analysis_url', 'mode', 'track_href', 'type', 'uri'])\n",
    "\n",
    "track_ids_90 = grouped_90['track.id'].tolist()\n",
    "track_str_90 = '%2C'.join(track_ids_90)\n",
    "t_90s = requests.get(\"https://api.spotify.com/v1/audio-features?ids=\" + track_str_90, headers={'Authorization': 'Bearer ' + token})\n",
    "track_info_90 = json_normalize(t_90s.json()['audio_features'])\n",
    "track_info_90 = track_info_90.drop(columns=['analysis_url', 'mode', 'track_href', 'type', 'uri'])\n",
    "\n",
    "track_ids_80 = grouped_80['track.id'].tolist()\n",
    "track_str_80 = '%2C'.join(track_ids_80)\n",
    "t_80s = requests.get(\"https://api.spotify.com/v1/audio-features?ids=\" + track_str_80, headers={'Authorization': 'Bearer ' + token})\n",
    "track_info_80 = json_normalize(t_80s.json()['audio_features'])\n",
    "track_info_80 = track_info_80.drop(columns=['analysis_url', 'mode', 'track_href', 'type', 'uri'])\n",
    "\n",
    "track_ids_70 = grouped_70['track.id'].tolist()\n",
    "track_str_70 = '%2C'.join(track_ids_70)\n",
    "t_70s = requests.get(\"https://api.spotify.com/v1/audio-features?ids=\" + track_str_70, headers={'Authorization': 'Bearer ' + token})\n",
    "track_info_70 = json_normalize(t_70s.json()['audio_features'])\n",
    "track_info_70 = track_info_70.drop(columns=['analysis_url', 'mode', 'track_href', 'type', 'uri'])\n",
    "\n",
    "track_ids_60 = grouped_60['track.id'].tolist()\n",
    "track_str_60 = '%2C'.join(track_ids_60)\n",
    "t_60s = requests.get(\"https://api.spotify.com/v1/audio-features?ids=\" + track_str_60, headers={'Authorization': 'Bearer ' + token})\n",
    "track_info_60 = json_normalize(t_60s.json()['audio_features'])\n",
    "track_info_60 = track_info_60.drop(columns=['analysis_url', 'mode', 'track_href', 'type', 'uri'])\n",
    "\n",
    "track_ids_50 = grouped_50['track.id'].tolist()\n",
    "track_str_50 = '%2C'.join(track_ids_50)\n",
    "t_50s = requests.get(\"https://api.spotify.com/v1/audio-features?ids=\" + track_str_50, headers={'Authorization': 'Bearer ' + token})\n",
    "track_info_50 = json_normalize(t_50s.json()['audio_features'])\n",
    "track_info_50 = track_info_50.drop(columns=['analysis_url', 'mode', 'track_href', 'type', 'uri'])\n",
    "\n",
    "grouped_50_index = grouped_50.index\n",
    "grouped_50.index = range(len(grouped_50))\n",
    "grouped_50[\"track.name\"] = grouped_50_index\n",
    "\n",
    "grouped_60_index = grouped_60.index\n",
    "grouped_60.index = range(len(grouped_60))\n",
    "grouped_60[\"track.name\"] = grouped_60_index\n",
    "\n",
    "grouped_70_index = grouped_70.index\n",
    "grouped_70.index = range(len(grouped_70))\n",
    "grouped_70[\"track.name\"] = grouped_70_index\n",
    "\n",
    "grouped_80_index = grouped_80.index\n",
    "grouped_80.index = range(len(grouped_80))\n",
    "grouped_80[\"track.name\"] = grouped_80_index\n",
    "\n",
    "grouped_90_index = grouped_90.index\n",
    "grouped_90.index = range(len(grouped_90))\n",
    "grouped_90[\"track.name\"] = grouped_90_index\n",
    "\n",
    "grouped_00_index = grouped_00.index\n",
    "grouped_00.index = range(len(grouped_00))\n",
    "grouped_00[\"track.name\"] = grouped_00_index\n",
    "\n",
    "#track.name appears to be in the index so we need to reindex it\n",
    "df_index = df_new.index\n",
    "df_new.index = range(len(df_new))\n",
    "df_new[\"track.name\"] = df_index\n",
    "\n",
    "print(grouped_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_2010s = pd.merge(df_new, track_info_df, left_on = 'track.id', right_on = 'id')\n",
    "data_2000s = pd.merge(grouped_00, track_info_00, left_on = 'track.id', right_on = 'id')\n",
    "data_1990s = pd.merge(grouped_90, track_info_90, left_on = 'track.id', right_on = 'id')\n",
    "data_1980s = pd.merge(grouped_80, track_info_80, left_on = 'track.id', right_on = 'id')\n",
    "data_1970s = pd.merge(grouped_70, track_info_70, left_on = 'track.id', right_on = 'id')\n",
    "data_1960s = pd.merge(grouped_60, track_info_60, left_on = 'track.id', right_on = 'id')\n",
    "data_1950s = pd.merge(grouped_50, track_info_50, left_on = 'track.id', right_on = 'id')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2010s['decade'] = '2010s'\n",
    "data_2000s['decade'] = '2000s'\n",
    "data_1990s['decade'] = '1990s'\n",
    "data_1980s['decade'] = '1980s'\n",
    "data_1970s['decade'] = '1970s'\n",
    "data_1960s['decade'] = '1960s'\n",
    "data_1950s['decade'] = '1950s'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decades_data = pd.concat([data_2010s, data_2000s, data_1990s, data_1980s, data_1970s, data_1960s, data_1950s])\n",
    "decades_data['energy'].groupby(decades_data['decade']).describe()\n",
    "decades_data # if track name doesn't show up, just restart the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decades_data['energy'].groupby(decades_data['decade']).mean().plot(kind='bar')\n",
    "plt.ylabel('Energy')\n",
    "plt.xlabel('Decade')\n",
    "plt.title('Energy in Songs Over Decades')\n",
    "plt.show()\n",
    "\n",
    "decades_data['track.popularity'].groupby(decades_data['decade']).mean().plot(kind='bar')\n",
    "plt.ylabel('Popoularity')\n",
    "plt.xlabel('Decade')\n",
    "plt.title('Popularity in Songs Over Decades')\n",
    "plt.show()\n",
    "\n",
    "decades_data['danceability'].groupby(decades_data['decade']).mean().plot(kind='bar')\n",
    "plt.ylabel('Danceability')\n",
    "plt.xlabel('Decade')\n",
    "plt.title('Danceability in Songs Over Decades')\n",
    "plt.show()\n",
    "\n",
    "decades_data['liveness'].groupby(decades_data['decade']).mean().plot(kind='bar')\n",
    "plt.ylabel('Liveness')\n",
    "plt.xlabel('Decade')\n",
    "plt.title('Liveness in Songs Over Decades')\n",
    "plt.show()\n",
    "\n",
    "decades_data['speechiness'].groupby(decades_data['decade']).mean().plot(kind='bar')\n",
    "plt.ylabel('Speechiness')\n",
    "plt.xlabel('Decade')\n",
    "plt.title('Speechiness in Songs Over Decades')\n",
    "plt.show()\n",
    "\n",
    "decades_data['instrumentalness'].groupby(decades_data['decade']).mean().plot(kind='bar')\n",
    "plt.ylabel('Instrumentalness')\n",
    "plt.xlabel('Decade')\n",
    "plt.title('Instrumentalness in Songs Over Decades')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decades_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decades_song(songs_arr, artist_arr):\n",
    "    lyr = \"\"\n",
    "    for song, artist in zip(songs_arr, artist_arr):\n",
    "        url = request_song_info(song, artist)\n",
    "        #print(\"URL: \"+url)\n",
    "        if url is not \"\": \n",
    "            lyr = get_cleaned_lyrics(url)\n",
    "    return lyr\n",
    "\n",
    "# trying to get song lyrics\n",
    "def request_song_info(song_title, artist_name):\n",
    "    base_url = 'https://api.genius.com'\n",
    "    headers = {'Authorization': 'Bearer ' + genius_token}\n",
    "    search_url = base_url + '/search'\n",
    "    data = {'q': song_title + ' ' + artist_name}\n",
    "    response = requests.get(search_url, data=data, headers=headers) # making the get request\n",
    "    json = response.json()\n",
    "    remote_song_info = None\n",
    "     \n",
    "    for hit in json['response']['hits']: #using the artist name to make sure we're actually getting the song we want\n",
    "        if artist_name.lower() in hit['result']['primary_artist']['name'].lower():\n",
    "            remote_song_info = hit\n",
    "            break\n",
    "        \n",
    "    if remote_song_info:     # Extract lyrics from URL if the song was found\n",
    "        song_url = remote_song_info['result']['url']\n",
    "        return song_url\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def get_cleaned_lyrics(url):\n",
    "    page = requests.get(url)\n",
    "    html = BeautifulSoup(page.text, 'html.parser')\n",
    "    lyrics = html.find('div', class_='lyrics').get_text()\n",
    "    tokens = word_tokenize(lyrics)\n",
    "    # convert to lower case\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    # remove punctuation from each word\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.add(\"chorus\")\n",
    "    stop_words.add(\"verse\")\n",
    "    stop_words.add(\"nt\")\n",
    "\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    return stop_words, words\n",
    "\n",
    "def generate_wordcloud(stop_words, words):\n",
    "    wordcloud = WordCloud(stopwords=stop_words, background_color=\"white\").generate(seven_years_lyrics)\n",
    "\n",
    "def display_wordcloud(wordcloud):\n",
    "    # Generate a word cloud image\n",
    "    # Display the generated image:\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decades_group = decades_data.groupby(\"decade\")\n",
    "decade_lyrics = {}\n",
    "for name, group in decades_group:\n",
    "    print(\"==========\")\n",
    "    #print(group[\"name\"])\n",
    "    lyr = decades_song(group[\"track.name\"], group[\"name\"])\n",
    "    print(lyr)\n",
    "    decade_lyrics[name] = lyr\n",
    "    # want to aggregate all of the lyrics for a decade\n",
    "\n",
    "decade_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
