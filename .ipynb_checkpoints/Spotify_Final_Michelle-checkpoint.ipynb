{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Through the Decades\n",
    "\n",
    "### Intro \n",
    "As I'm typing this introduction, I'm bopping to \"Holiday\" by Green Day, on a random \"Pump Up Music\" playlist that I found 5 minutes ago (thank you apache_king!). Music has played and continues to play a very important part of my life. I've been jamming to something or the other since first grade, learned to play the guitar in second grade, and have been in every band I possibly could throughout elementary, middle, and high school. Ever since starting college, I've gone to over 10 different concerts, and much to my roommates' consternation, every time I shower I blare anything from Imagine Dragons to Logic to Linkin Park to Queen (and badly sing to it). \n",
    "\n",
    "Needless to say, music is important to me. It's how I process my emotions when I'm upset, motivate myself when I feel lazy, and run the extra 3 minutes (because running the extra mile is too much to ask for) when I'm sweating it out at the gym. I'm sure I'm not the only one like this either. The emotions of a generation are forever captured by the popularity of songs of that time. Music has come to define eras and decades, like the psychedlic rock of the Beatles dominating the 60s, the eccentric theatric rock of Queen of the 80s, and even artists like NSYNC coming to embody the odd time that was the 90s. \n",
    "\n",
    "### Goals of the Project\n",
    "We thought it would be interesting to see if there were changes between the popular music of the decades from the 50s through the 2010s. With every generation facing a different landscape, from the post-war economic boom in the 50s to recession in the late 2000s, we thought it would be interesting to explore whether changes in music reflected that. Would the uncertainty of a war with Russia in the 80s drive people to seek out more angry or sad music? Would the happiness after the end of World War 2 be reflected in the popularity of the songs in that era? By that token, by analyzing the popular songs of these decades, can we build a classifier that could predict the era a song was created in based off of its audio features? \n",
    "\n",
    "### How We Will Do This\n",
    "Using Spotify and Genius's Web APIs, we wanted to explore these questions and present a case study in the changes in popular music over the decades. We will use Spotify's own \"All Out\" playlists, which are organized by decade. We felt that these playlists would prove a promising source of information about the popular songs of a certain decade. We will use Spotify's API to be able to gain information about the features of the track, from danceability to 'speechiness'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step One : Imports\n",
    "The first thing we did was import everything that we needed. Because we were accessing the Spotify and Genius APIs, we use the requests library as well as others to be able to parse the information we query into a dataframe. There is a spotify library for python called spotipy, but we realized that there was not huge benefit from using that library instead of just using requests and get calls to the API endpoint. We will also later use the Natural Language ToolKit (or NLTK) to meaningfully analyze text, so we download the necessary modules from within that as well. Lastly, for preliminary machine learning, we also imported different modules within SciKit-Learn. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.6/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting wordcloud\n",
      "  Downloading https://files.pythonhosted.org/packages/ae/af/849edf14d573eba9c8082db898ff0d090428d9485371cc4fe21a66717ad2/wordcloud-1.5.0-cp36-cp36m-manylinux1_x86_64.whl (361kB)\n",
      "\u001b[K    100% |████████████████████████████████| 368kB 1.2MB/s ta 0:00:01    51% |████████████████▎               | 184kB 6.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.6.1 in /opt/conda/lib/python3.6/site-packages (from wordcloud)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.6/site-packages (from wordcloud)\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.5.0\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting nltk\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/ed/9c755d357d33bc1931e157f537721efb5b88d2c583fe593cc09603076cc3/nltk-3.4.zip (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 148kB/s ta 0:00:011\n",
      "\u001b[?25hCollecting six (from nltk)\n",
      "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Requirement already up-to-date: singledispatch in /opt/conda/lib/python3.6/site-packages (from nltk)\n",
      "Building wheels for collected packages: nltk\n",
      "  Running setup.py bdist_wheel for nltk ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/4b/c8/24/b2343664bcceb7147efeb21c0b23703a05b23fcfeaceaa2a1e\n",
      "Successfully built nltk\n",
      "Installing collected packages: six, nltk\n",
      "  Found existing installation: six 1.11.0\n",
      "    Uninstalling six-1.11.0:\n",
      "      Successfully uninstalled six-1.11.0\n",
      "Successfully installed nltk-3.4 six-1.12.0\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# Request / Parsing \n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from pandas.io.json import json_normalize\n",
    "import string\n",
    "\n",
    "#Visualization and EDA \n",
    "import sys \n",
    "# The below 3 statements were only done because we were coding within a Jupyter notebook set up for our class (CMSC320). \n",
    "# For those following at home, you will likely just need to pip install these in your command-line, instead of within \n",
    "# the confines of the notebook itself. \n",
    "\n",
    "!{sys.executable} -m pip install Pillow  \n",
    "!{sys.executable} -m pip install wordcloud\n",
    "!{sys.executable} -m pip install -U nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import seaborn as sns\n",
    "\n",
    "#Machine Learning \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: Gaining Access to the Spotify and Genius Web APIs \n",
    "To be able to continue with this project, you need authentification tokens provided through Spotify. We would periodically request tokens from this website : https://developer.spotify.com/console/get-playlist-tracks/?playlist_id=37i9dQZF1DX5Ejj0EkURtP&market=&fields=&limit=&offset= to query Spotify. This requires a Spotify account. Similarly, Genius's API requires an account as well. We used this website: https://docs.genius.com/#/getting-started-h1 to set up our own accounts. \n",
    "\n",
    "Afterwards, store the tokens within variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://developer.spotify.com/console/get-playlist-tracks/?playlist_id=37i9dQZF1DX5Ejj0EkURtP&market=&fields=&limit=&offset= \n",
    "# use above website to generate token\n",
    "token = \"BQBHofH0ofj5PCnzD0he_SNu8ct2FpJVbnPsNs0Pg5SLfwAsDdNn64Mg7-NhJwp1-SzPKdPIjMmq4u_BqjAY4FbHQeh9OnRAhAjQabPlm4ukIFdrYBm0S-o1wlK37u75zXY_SOE8pV6xSeh2EQ\"\n",
    "# https://genius.com/api-clients ==> use this website to generate token\n",
    "genius_token = 'V3BxSvKtWKcSlonUDfqeKWZmRKK3qjGyAGJCRqxm8awvuWI65nm7WFrYmnn3acIu'\n",
    "\n",
    "# token = \"INSERT SPOTIFY TOKEN HERE\"\n",
    "# genius_token = \"INSERT GENIUS TOKEN HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: Getting the Information Into a Dataframe\n",
    "We used two different endpoints to get the necessary data to analyze the trends over time. The first one was to grab the decades playlist provided by Spotify from the 50s to the 2010s. These playlists list the most popular songs of the decade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_10s = requests.get(\"https://api.spotify.com/v1/playlists/37i9dQZF1DX5Ejj0EkURtP\", headers={'Authorization': 'Bearer ' + token})\n",
    "r_00s = requests.get(\"https://api.spotify.com/v1/playlists/37i9dQZF1DX4o1oenSJRJd\", headers={'Authorization': 'Bearer ' + token})\n",
    "r_90s = requests.get(\"https://api.spotify.com/v1/playlists/37i9dQZF1DXbTxeAdrVG2l\", headers={'Authorization': 'Bearer ' + token})\n",
    "r_80s = requests.get(\"https://api.spotify.com/v1/playlists/37i9dQZF1DX4UtSsGT1Sbe\", headers={'Authorization': 'Bearer ' + token})\n",
    "r_70s = requests.get(\"https://api.spotify.com/v1/playlists/37i9dQZF1DWTJ7xPn4vNaz\", headers={'Authorization': 'Bearer ' + token})\n",
    "r_60s = requests.get(\"https://api.spotify.com/v1/playlists/37i9dQZF1DXaKIA8E7WcJj\", headers={'Authorization': 'Bearer ' + token})\n",
    "r_50s = requests.get(\"https://api.spotify.com/v1/playlists/37i9dQZF1DWSV3Tk4GO2fq\", headers={'Authorization': 'Bearer ' + token})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the Data\n",
    "We had to get the data into a form that is more readily understandable. The data returned from the playlist endpoint is in JSON format and many important data points very nested inside the JSON object. The code below is grabbing the important data from the JSON returned from each call to the API, grabbing those nested data points as well, and converting it into multiple dataframes. This shows the results for the 2010s playlist. We then replicated it for all of the other decades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tracks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a002fd37d238>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mjson_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_10s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplaylists_10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tracks\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"items\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'track'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'artists'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'added_at'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'track'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'popularity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'track'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'track'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'track'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'duration_ms'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplaylists_10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplaylists_10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'external_urls'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'href'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'uri'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplaylists_10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tracks'"
     ]
    }
   ],
   "source": [
    "json_data = r_10s.json()\n",
    "playlists_10 = json_normalize(json_data[\"tracks\"][\"items\"], [['track', 'artists']], ['added_at', ['track', 'popularity'], ['track', 'id'], ['track', 'name'], ['track', 'duration_ms']], errors='ignore')\n",
    "playlists_10 = playlists_10.drop(columns=['external_urls', 'href', 'type', 'uri'])\n",
    "\n",
    "playlists_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "json_data = r_10s.json()\n",
    "playlists_10 = json_normalize(json_data[\"tracks\"][\"items\"], [['track', 'artists']], ['added_at', ['track', 'popularity'], ['track', 'id'], ['track', 'name'], ['track', 'duration_ms']], errors='ignore')\n",
    "playlists_10 = playlists_10.drop(columns=['external_urls', 'href', 'type', 'uri'])\n",
    "\n",
    "json_data_00 = r_00s.json()\n",
    "playlists_00 = json_normalize(json_data_00[\"tracks\"][\"items\"], [['track', 'artists']], ['added_at', ['track', 'popularity'], ['track', 'id'], ['track', 'name'], ['track', 'duration_ms']], errors='ignore')\n",
    "playlists_00 = playlists_00.drop(columns=['external_urls', 'href', 'type', 'uri'])\n",
    "\n",
    "json_data_90 = r_90s.json()\n",
    "playlists_90 = json_normalize(json_data_90[\"tracks\"][\"items\"], [['track', 'artists']], ['added_at', ['track', 'popularity'], ['track', 'id'], ['track', 'name'], ['track', 'duration_ms']], errors='ignore')\n",
    "playlists_90 = playlists_90.drop(columns=['external_urls', 'href', 'type', 'uri'])\n",
    "\n",
    "json_data_80 = r_80s.json()\n",
    "playlists_80 = json_normalize(json_data_80[\"tracks\"][\"items\"], [['track', 'artists']], ['added_at', ['track', 'popularity'], ['track', 'id'], ['track', 'name'], ['track', 'duration_ms']], errors='ignore')\n",
    "playlists_80 = playlists_80.drop(columns=['external_urls', 'href', 'type', 'uri'])\n",
    "\n",
    "json_data_70 = r_70s.json()\n",
    "playlists_70 = json_normalize(json_data_70[\"tracks\"][\"items\"], [['track', 'artists']], ['added_at', ['track', 'popularity'], ['track', 'id'], ['track', 'name'], ['track', 'duration_ms']], errors='ignore')\n",
    "playlists_70 = playlists_70.drop(columns=['external_urls', 'href', 'type', 'uri'])\n",
    "\n",
    "json_data_60 = r_60s.json()\n",
    "playlists_60 = json_normalize(json_data_60[\"tracks\"][\"items\"], [['track', 'artists']], ['added_at', ['track', 'popularity'], ['track', 'id'], ['track', 'name'], ['track', 'duration_ms']], errors='ignore')\n",
    "playlists_60 = playlists_60.drop(columns=['external_urls', 'href', 'type', 'uri'])\n",
    "\n",
    "json_data_50 = r_50s.json()\n",
    "playlists_50 = json_normalize(json_data_50[\"tracks\"][\"items\"], [['track', 'artists']], ['added_at', ['track', 'popularity'], ['track', 'id'], ['track', 'name'], ['track', 'duration_ms']], errors='ignore')\n",
    "playlists_50 = playlists_50.drop(columns=['external_urls', 'href', 'type', 'uri'])\n",
    "\n",
    "playlists_80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Music Attributes\n",
    "Now that we have the information about each playlist, we want to grab information for each track inside the playlists. The code below makes a list of all the track ids in the playlists and uses that to call to the second end point we use: the audio features end point. This end point will give a good amount of information such, the valence, the tempo, the danceability, the instrumentalness, the speechiness, and the energy of each of the songs in the playlist and convert it into a dataframe. However, this endpoint will also give us unnecessary information such as the mode, track_href, uri, and analysis url of the song, which is not useful for our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aggregation_functions = {'name': 'first', 'track.id': 'first', 'track.duration_ms': 'first', 'added_at': 'first', 'track.popularity' : 'first'}\n",
    "df_new = playlists_10.groupby(playlists_10['track.name']).aggregate(aggregation_functions)\n",
    "\n",
    "aggregation_functions = {'name': 'first', 'track.id': 'first', 'track.duration_ms': 'first', 'added_at': 'first', 'track.popularity' : 'first'}\n",
    "grouped_00 = playlists_00.groupby(playlists_00['track.name']).aggregate(aggregation_functions)\n",
    "\n",
    "aggregation_functions = {'name': 'first', 'track.id': 'first', 'track.duration_ms': 'first', 'added_at': 'first', 'track.popularity' : 'first'}\n",
    "grouped_90 = playlists_90.groupby(playlists_90['track.name']).aggregate(aggregation_functions)\n",
    "\n",
    "aggregation_functions = {'name': 'first', 'track.id': 'first', 'track.duration_ms': 'first', 'added_at': 'first', 'track.popularity' : 'first'}\n",
    "grouped_80 = playlists_80.groupby(playlists_80['track.name']).aggregate(aggregation_functions)\n",
    "\n",
    "aggregation_functions = {'name': 'first', 'track.id': 'first', 'track.duration_ms': 'first', 'added_at': 'first', 'track.popularity' : 'first'}\n",
    "grouped_70 = playlists_70.groupby(playlists_70['track.name']).aggregate(aggregation_functions)\n",
    "\n",
    "aggregation_functions = {'name': 'first', 'track.id': 'first', 'track.duration_ms': 'first', 'added_at': 'first', 'track.popularity' : 'first'}\n",
    "grouped_60 = playlists_60.groupby(playlists_60['track.name']).aggregate(aggregation_functions)\n",
    "\n",
    "aggregation_functions = {'name': 'first', 'track.id': 'first', 'track.duration_ms': 'first', 'added_at': 'first', 'track.popularity' : 'first'}\n",
    "grouped_50 = playlists_50.groupby(playlists_50['track.name']).aggregate(aggregation_functions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "track_ids = df_new['track.id'].tolist()\n",
    "track_str = '%2C'.join(track_ids)\n",
    "t = requests.get(\"https://api.spotify.com/v1/audio-features?ids=\" + track_str, headers={'Authorization': 'Bearer ' + token})\n",
    "track_info_df = json_normalize(t.json()['audio_features'])\n",
    "track_info_df = track_info_df.drop(columns=['analysis_url', 'mode', 'track_href', 'type', 'uri'])\n",
    "\n",
    "track_ids_00 = grouped_00['track.id'].tolist()\n",
    "track_str_00 = '%2C'.join(track_ids_00)\n",
    "t_00s = requests.get(\"https://api.spotify.com/v1/audio-features?ids=\" + track_str_00, headers={'Authorization': 'Bearer ' + token})\n",
    "track_info_00 = json_normalize(t_00s.json()['audio_features'])\n",
    "track_info_00 = track_info_00.drop(columns=['analysis_url', 'mode', 'track_href', 'type', 'uri'])\n",
    "\n",
    "track_ids_90 = grouped_90['track.id'].tolist()\n",
    "track_str_90 = '%2C'.join(track_ids_90)\n",
    "t_90s = requests.get(\"https://api.spotify.com/v1/audio-features?ids=\" + track_str_90, headers={'Authorization': 'Bearer ' + token})\n",
    "track_info_90 = json_normalize(t_90s.json()['audio_features'])\n",
    "track_info_90 = track_info_90.drop(columns=['analysis_url', 'mode', 'track_href', 'type', 'uri'])\n",
    "\n",
    "track_ids_80 = grouped_80['track.id'].tolist()\n",
    "track_str_80 = '%2C'.join(track_ids_80)\n",
    "t_80s = requests.get(\"https://api.spotify.com/v1/audio-features?ids=\" + track_str_80, headers={'Authorization': 'Bearer ' + token})\n",
    "track_info_80 = json_normalize(t_80s.json()['audio_features'])\n",
    "track_info_80 = track_info_80.drop(columns=['analysis_url', 'mode', 'track_href', 'type', 'uri'])\n",
    "\n",
    "track_ids_70 = grouped_70['track.id'].tolist()\n",
    "track_str_70 = '%2C'.join(track_ids_70)\n",
    "t_70s = requests.get(\"https://api.spotify.com/v1/audio-features?ids=\" + track_str_70, headers={'Authorization': 'Bearer ' + token})\n",
    "track_info_70 = json_normalize(t_70s.json()['audio_features'])\n",
    "track_info_70 = track_info_70.drop(columns=['analysis_url', 'mode', 'track_href', 'type', 'uri'])\n",
    "\n",
    "track_ids_60 = grouped_60['track.id'].tolist()\n",
    "track_str_60 = '%2C'.join(track_ids_60)\n",
    "t_60s = requests.get(\"https://api.spotify.com/v1/audio-features?ids=\" + track_str_60, headers={'Authorization': 'Bearer ' + token})\n",
    "track_info_60 = json_normalize(t_60s.json()['audio_features'])\n",
    "track_info_60 = track_info_60.drop(columns=['analysis_url', 'mode', 'track_href', 'type', 'uri'])\n",
    "\n",
    "track_ids_50 = grouped_50['track.id'].tolist()\n",
    "track_str_50 = '%2C'.join(track_ids_50)\n",
    "t_50s = requests.get(\"https://api.spotify.com/v1/audio-features?ids=\" + track_str_50, headers={'Authorization': 'Bearer ' + token})\n",
    "track_info_50 = json_normalize(t_50s.json()['audio_features'])\n",
    "track_info_50 = track_info_50.drop(columns=['analysis_url', 'mode', 'track_href', 'type', 'uri'])\n",
    "\n",
    "#track.name appears to be in the index so we need to reindex it\n",
    "grouped_50_index = grouped_50.index\n",
    "grouped_50.index = range(len(grouped_50))\n",
    "grouped_50[\"track.name\"] = grouped_50_index\n",
    "\n",
    "grouped_60_index = grouped_60.index\n",
    "grouped_60.index = range(len(grouped_60))\n",
    "grouped_60[\"track.name\"] = grouped_60_index\n",
    "\n",
    "grouped_70_index = grouped_70.index\n",
    "grouped_70.index = range(len(grouped_70))\n",
    "grouped_70[\"track.name\"] = grouped_70_index\n",
    "\n",
    "grouped_80_index = grouped_80.index\n",
    "grouped_80.index = range(len(grouped_80))\n",
    "grouped_80[\"track.name\"] = grouped_80_index\n",
    "\n",
    "grouped_90_index = grouped_90.index\n",
    "grouped_90.index = range(len(grouped_90))\n",
    "grouped_90[\"track.name\"] = grouped_90_index\n",
    "\n",
    "grouped_00_index = grouped_00.index\n",
    "grouped_00.index = range(len(grouped_00))\n",
    "grouped_00[\"track.name\"] = grouped_00_index\n",
    "\n",
    "df_index = df_new.index\n",
    "df_new.index = range(len(df_new))\n",
    "df_new[\"track.name\"] = df_index\n",
    "\n",
    "print(grouped_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have two groups of dataframes: the dataframes with each decade's playlist information, and the dataframes with all the song information for each decade. Now we want to merge the on a common columns between the two which would be the track id column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2010s = pd.merge(df_new, track_info_df, left_on = 'track.id', right_on = 'id')\n",
    "data_2000s = pd.merge(grouped_00, track_info_00, left_on = 'track.id', right_on = 'id')\n",
    "data_1990s = pd.merge(grouped_90, track_info_90, left_on = 'track.id', right_on = 'id')\n",
    "data_1980s = pd.merge(grouped_80, track_info_80, left_on = 'track.id', right_on = 'id')\n",
    "data_1970s = pd.merge(grouped_70, track_info_70, left_on = 'track.id', right_on = 'id')\n",
    "data_1960s = pd.merge(grouped_60, track_info_60, left_on = 'track.id', right_on = 'id')\n",
    "data_1950s = pd.merge(grouped_50, track_info_50, left_on = 'track.id', right_on = 'id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to add another column named decade to be able to differentiate between the different decades when we combine all dataframes into one large dataframe with all the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2010s['decade'] = '2010s'\n",
    "data_2000s['decade'] = '2000s'\n",
    "data_1990s['decade'] = '1990s'\n",
    "data_1980s['decade'] = '1980s'\n",
    "data_1970s['decade'] = '1970s'\n",
    "data_1960s['decade'] = '1960s'\n",
    "data_1950s['decade'] = '1950s'\n",
    "\n",
    "# In the code below, we combine all the dataframes into one large dataframe\n",
    "decades_data = pd.concat([data_2010s, data_2000s, data_1990s, data_1980s, data_1970s, data_1960s, data_1950s])\n",
    "decades_data['energy'].groupby(decades_data['decade']).describe()\n",
    "# fixing the index\n",
    "decades_data.index = range(len(decades_data))\n",
    "decades_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Exploratory Data Analysis\n",
    "The following code gives a visualization of the trends in the different aspects of music using the averages in the large dataframe over the different audio features of the tracks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"1950s\", \"1960s\", \"1970s\", \"1980s\", \"1990s\", \"2000s\", \"2010s\"]\n",
    "\n",
    "decades_data['energy'].groupby(decades_data['decade']).mean().plot(kind='line')\n",
    "decades_data['energy'].groupby(decades_data['decade']).mean().plot(kind='bar')\n",
    "plt.ylabel('Energy')\n",
    "plt.xlabel('Decade')\n",
    "plt.title('Energy in Songs Over Decades')\n",
    "plt.show()\n",
    "\n",
    "decades_data['track.popularity'].groupby(decades_data['decade']).mean().plot(kind='line')\n",
    "decades_data['track.popularity'].groupby(decades_data['decade']).mean().plot(kind='bar')\n",
    "plt.ylabel('Popoularity')\n",
    "plt.xlabel('Decade')\n",
    "plt.title('Popularity in Songs Over Decades')\n",
    "plt.show()\n",
    "\n",
    "decades_data['danceability'].groupby(decades_data['decade']).mean().plot(kind='line')\n",
    "decades_data['danceability'].groupby(decades_data['decade']).mean().plot(kind='bar')\n",
    "plt.ylabel('Danceability')\n",
    "plt.xlabel('Decade')\n",
    "plt.title('Danceability in Songs Over Decades')\n",
    "plt.show()\n",
    "\n",
    "decades_data['liveness'].groupby(decades_data['decade']).mean().plot(kind='line')\n",
    "decades_data['liveness'].groupby(decades_data['decade']).mean().plot(kind='bar')\n",
    "plt.ylabel('Liveness')\n",
    "plt.xlabel('Decade')\n",
    "plt.title('Liveness in Songs Over Decades')\n",
    "plt.show()\n",
    "\n",
    "decades_data['speechiness'].groupby(decades_data['decade']).mean().plot(kind='line')\n",
    "decades_data['speechiness'].groupby(decades_data['decade']).mean().plot(kind='bar')\n",
    "plt.ylabel('Speechiness')\n",
    "plt.xlabel('Decade')\n",
    "plt.title('Speechiness in Songs Over Decades')\n",
    "plt.show()\n",
    "\n",
    "decades_data['instrumentalness'].groupby(decades_data['decade']).mean().plot(kind='line')\n",
    "decades_data['instrumentalness'].groupby(decades_data['decade']).mean().plot(kind='bar')\n",
    "plt.ylabel('Instrumentalness')\n",
    "plt.xlabel('Decade')\n",
    "plt.title('Instrumentalness in Songs Over Decades')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This is comparing the instrumentalness to the liveness of the music, to see whether there appears to be an inverse \n",
    "# relation between the two\n",
    "\n",
    "test = decades_data['instrumentalness'].groupby(decades_data['decade']).mean().to_frame()\n",
    "test[\"liveness\"] = decades_data['liveness'].groupby(decades_data['decade']).mean()\n",
    "test[\"energy\"] = decades_data['energy'].groupby(decades_data['decade']).mean()\n",
    "test[\"popularity\"] = decades_data['track.popularity'].groupby(decades_data['decade']).mean()\n",
    "test[\"danceability\"] = decades_data['danceability'].groupby(decades_data['decade']).mean()\n",
    "test[\"speechiness\"] = decades_data['speechiness'].groupby(decades_data['decade']).mean()\n",
    "test['duration_ms'] = decades_data['duration_ms'].groupby(decades_data['decade']).mean()\n",
    "\n",
    "test.plot.line(y=['instrumentalness', 'speechiness'])\n",
    "plt.xticks([0,1,2,3,4,5,6, 7], test.index.values.tolist())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing each Decade's Profile\n",
    "Spotify's API gives us a number of features to characterize a track by. To name a few metrics that Spotify tracks for each song, you could find out the level of acousticness, loudness, tempo, and regularity for a particular track. All of these audio features play an essential part in the unique make up for a track and it would be good to start off our data analysis with a big picture of how songs in each decade compares to each other overall. We decided to create radar charts to chart a few key measures that we felt were interesting and could characterize the popular songs from each decade. \n",
    "\n",
    "Each decade's profile is in the form of a radar chart that gives the average energy, speechiness, instrumentalness, danceability, and liveness for the popular songs of a certain decade.\n",
    "\n",
    "Energy, speechiness, valence, danceability, and instrumentalness are all values on a scale from 0 to 1. Energy describes the intensity of a track. Tracks with high energy feel fast, loud, or noisy. Speechiness describes the presence of spoken words in a track. Valence describes the positiveness that is conveyed by a track. High valence is an indication of a happier song while low valence is an indication of a more sad or angry song, Danceability describes how suitable a track is for dancing using musical elements like temp, beat strength, and regularity. Instrumentalness describes the degree to which a song has no vocals.\n",
    "\n",
    "We produced radar charts for each decade starting from the 1950s up to the 2010a, each giving a general overview of how each audio feature's performance makes up a song of a decade in a wholistic evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Creating a Radar Chart for the metrics of the average song in a particular decade\n",
    "mean_stats = pd.DataFrame()\n",
    "\n",
    "# Obtaining mean for each metric for all the popular songs in a decade\n",
    "mean_stats['energy'] = decades_data['energy'].groupby(decades_data['decade']).mean()\n",
    "mean_stats['speechiness'] = decades_data['speechiness'].groupby(decades_data['decade']).mean()\n",
    "mean_stats['instrumentalness'] = decades_data['instrumentalness'].groupby(decades_data['decade']).mean()\n",
    "mean_stats['danceability'] = decades_data['danceability'].groupby(decades_data['decade']).mean()\n",
    "mean_stats['valence'] = decades_data['valence'].groupby(decades_data['decade']).mean()\n",
    "\n",
    "\n",
    "# Standardizing all the metrics so they can be scaled relative to each other in the \n",
    "# radar chart\n",
    "for name, values in mean_stats.iteritems():\n",
    "    mean = values.mean()\n",
    "    std1 = values.std()\n",
    "    mean_stats[name] = (values - mean)/std1\n",
    "\n",
    "mean_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, python itself does not have built in functionalities that create radar charts. Luckily, we were able to create radar charts following this tutortial from Kaggle. \n",
    "\n",
    "    Draw a Radar Chart with Python in a Simple Way\n",
    "    by Chen ShuyaoDraw\n",
    "    (https://www.kaggle.com/typewind/draw-a-radar-chart-with-python-in-a-simple-way)\n",
    "\n",
    "You can follow it too and create your own radar charts in performance analysis,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the radar charts\n",
    "labels=np.array(['energy', 'speechiness', 'instrumentalness', 'danceability', 'valence'])\n",
    "colors=np.array(['blue', 'orange', 'green', 'red', 'purple', 'brown', 'pink'])\n",
    "\n",
    "for i in range(7):\n",
    "    # sets up the axes\n",
    "    stats=mean_stats.iloc[i].values\n",
    "    angles=np.linspace(0, 2*np.pi, len(labels), endpoint=False)\n",
    "    \n",
    "    # creates a closed plot\n",
    "    angles=np.concatenate((angles,[angles[0]]))\n",
    "    stats=np.concatenate((stats,[stats[0]]))\n",
    "    fig=plt.figure()\n",
    "    \n",
    "    # when adding a subplot, make the polar parameter True to plot the subplot on\n",
    "    # the radial axes\n",
    "    ax = fig.add_subplot(111, polar=True)\n",
    "    ax.plot(angles, stats, '-o', color = colors[i])\n",
    "    ax.fill(angles, stats, alpha=0.2, color = colors[i])\n",
    "    ax.set_thetagrids(angles * 180/np.pi, labels)\n",
    "    ax.set_title([mean_stats.index[i] + \" Radar Chart\"])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.grid(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final radar charts produced allows us to visualize a profile of energy, liveness, danceability, instrumentalness, and speechiness for the popular songs of each decade. The changes in shape across the decades reveal several distinct similaries and differences in track structure and musical content from the 1950s to the 2010s.\n",
    "\n",
    "One can immediately group some of the decades in this period together due to the similar shape of their profiles. The shape of 1950s and 1960s profiles are very similar. For both the 1950s and the 1960s, tracks had high instrumentalness and valence, medium speechiness and energy (energy is lower for 1960s), and low danceability. Then in the 1970s, speechiness drops considerably while danceability and energy become more pronounced. The 1970s have high instrumentalness and valence, medium energy and danceability, and low speechiness. \n",
    "\n",
    "The transition between the 1970s and 1980s shows a significant change in the track structure and audio features of popular songs. There is a drop in instrumentalness and valence and there is an increase in energy and danceability. The 1980s specifically had high energy and danceability, medium instrumentalness and valence, and low speechiness. Medium/low instrumentalness and valence and medium/high energy and danceability will persist for the decades after the 1980s. \n",
    "\n",
    "The shapes of the radar charts for the 1990s, 2000s, and 2010s are similar. The three decades all have low instrumentalness and valence and high energy and danceability. The 1990s had a low speechiness while the 2000s and 2010s had high speechiness. The profile shape for the 2000s and 2010s are almost indiscernible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trending Danceability, Speechiness, and Energy across the Decades\n",
    "How exactly do we know that a song is popular? Spotify and other radio often curate these lists based on the how often the song was played amongst various media outlets. We imagined the types of occasions that we, as general music consumers, like to play music at and what makes a song so catchy or fitting for singing along to in the car or swaying those hips at dance functions. Perhaps there is some relationship between the danceability, speechiness, and energy of songs across the decades.\n",
    "\n",
    "We created a scatterplot to compare the danceability, speechiness, and energy of songs from the 1950s to the 2010s. Energy, the intensity of a track, varies along the y axis. Danceability is noted by the hue of the color blue. Light blue means the track is of low danceability while dark blue means the track is of high danceability. Speechiness, the presence of spoken words in a track, is marked by the size of the data point. Bigger data points indicate that the track has more spoken words than tracks marked by smaller data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a scatterplot for 4 variables\n",
    "cmap = sns.cubehelix_palette(rot=-.2, as_cmap=True)\n",
    "ax = sns.scatterplot(x=\"decade\", y=\"danceability\",\n",
    "                     hue=\"energy\", size=\"speechiness\",\n",
    "                     palette=cmap, sizes=(10, 200),\n",
    "                     data=decades_data)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1, 0.5, 0.5, 0.5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the decades, the danceability of popular tracks have increased as there is a slight upward movement in the range of danceability for tracks over time. The 2000s stands out as the decade with the most speechiness and energy since its plots have some of the largest and darkest data points. In contrast, the 1960s stands out as the decade with popular tracks that have the lowest energy and speechiness due to the light color and small size of its data points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##pretty but don't use\n",
    "\n",
    "ax = sns.scatterplot(x=\"energy\", y=\"danceability\",\n",
    "                     hue=\"speechiness\", size=\"decade\",\n",
    "                     palette=cmap, sizes=(10, 200),\n",
    "                     data=decades_data)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1, 0.5, 0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
